{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fscil_adsp_cfr_full.py\n",
    "# Fully functional FSCIL (ADSP-CFR style) reference implementation.\n",
    "# Runs end-to-end on CIFAR-100 by default.\n",
    "#\n",
    "# Key modules:\n",
    "# - Plastic stream (trainable backbone + session prompt)\n",
    "# - Stable stream (EMA backbone + base prompt) as teacher/memory\n",
    "# - Prototype Memory + NCM classifier\n",
    "# - Losses: CE + proto + KD + domain\n",
    "#\n",
    "# NOTE: This is a research-grade reference implementation (not SOTA optimized).\n",
    "# It is designed to be clear, correct, and runnable.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aea29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "def seed_all(seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4381a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:\n",
    "    return x / (x.norm(p=2, dim=dim, keepdim=True) + eps)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher: nn.Module, student: nn.Module, alpha: float):\n",
    "    \"\"\"teacher = alpha*teacher + (1-alpha)*student\"\"\"\n",
    "    t_params = dict(teacher.named_parameters())\n",
    "    for name, p_s in student.named_parameters():\n",
    "        p_t = t_params[name]\n",
    "        p_t.data.mul_(alpha).add_(p_s.data, alpha=(1.0 - alpha))\n",
    "\n",
    "\n",
    "def set_requires_grad(module: nn.Module, flag: bool):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b52d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Dataset: MiniImageNet (optional)\n",
    "# Folder structure expected:\n",
    "# root/\n",
    "#   train/class_x/xxx.png ...\n",
    "#   test/class_x/xxx.png ...\n",
    "#   val/class_x/xxx.png ...\n",
    "# ---------------------------\n",
    "class MiniImageNetFolder(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root_split: str, transform=None):\n",
    "        super().__init__(root=root_split, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfafd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Split FSCIL sessions\n",
    "# ---------------------------\n",
    "def make_fscil_splits(\n",
    "    targets: List[int],\n",
    "    base_classes: int = 40,\n",
    "    ways_per_session: int = 5,\n",
    "    shots_per_class: int = 5,\n",
    "    seed: int = 0,\n",
    ") -> Tuple[List[int], List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      base_class_ids: list of class ids in base session\n",
    "      inc_sessions: list of sessions, each session is list of class ids\n",
    "    \"\"\"\n",
    "    seed_all(seed)\n",
    "    classes = sorted(list(set(targets)))\n",
    "    assert len(classes) >= base_classes, \"Not enough classes.\"\n",
    "\n",
    "    #random.shuffle(classes)\n",
    "    base_cls = classes[:base_classes]\n",
    "    remaining = classes[base_classes:]\n",
    "\n",
    "    inc_sessions = []\n",
    "    for i in range(0, len(remaining), ways_per_session):\n",
    "        sess = remaining[i:i + ways_per_session]\n",
    "        if len(sess) == ways_per_session:\n",
    "            inc_sessions.append(sess)\n",
    "\n",
    "    return base_cls, inc_sessions\n",
    "\n",
    "\n",
    "def indices_for_classes(targets: List[int], class_ids: List[int]) -> List[int]:\n",
    "    s = set(class_ids)\n",
    "    return [i for i, y in enumerate(targets) if y in s]\n",
    "\n",
    "\n",
    "def fewshot_indices_for_classes(\n",
    "    targets: List[int],\n",
    "    class_ids: List[int],\n",
    "    shots_per_class: int,\n",
    "    seed: int = 0\n",
    ") -> List[int]:\n",
    "    seed_all(seed)\n",
    "    idxs = []\n",
    "    for c in class_ids:\n",
    "        all_idx = [i for i, y in enumerate(targets) if y == c]\n",
    "        random.shuffle(all_idx)\n",
    "        idxs.extend(all_idx[:shots_per_class])\n",
    "    return idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83136bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Memory buffer for replay\n",
    "# ---------------------------\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_per_class: int = 20, seed: int = 0):\n",
    "        self.max_per_class = max_per_class\n",
    "        self.seed = seed\n",
    "        self.storage: Dict[int, List[int]] = {}  # class_id -> list of dataset indices\n",
    "\n",
    "    def add_indices(self, targets: List[int], new_indices: List[int]):\n",
    "        # store up to max_per_class per class\n",
    "        for idx in new_indices:\n",
    "            c = targets[idx]\n",
    "            if c not in self.storage:\n",
    "                self.storage[c] = []\n",
    "            self.storage[c].append(idx)\n",
    "\n",
    "        # trim\n",
    "        seed_all(self.seed)\n",
    "        for c in list(self.storage.keys()):\n",
    "            lst = self.storage[c]\n",
    "            random.shuffle(lst)\n",
    "            self.storage[c] = lst[: self.max_per_class]\n",
    "\n",
    "    def all_indices(self) -> List[int]:\n",
    "        out = []\n",
    "        for c, lst in self.storage.items():\n",
    "            out.extend(lst)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Prompt module (learnable tokens)\n",
    "# ---------------------------\n",
    "class PromptModule(nn.Module):\n",
    "    \"\"\"\n",
    "    prompts: [m, D]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_prompts: int, dim: int, init_std: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.prompts = nn.Parameter(torch.randn(num_prompts, dim) * init_std)\n",
    "\n",
    "    def forward(self, B: int) -> torch.Tensor:\n",
    "        return self.prompts.unsqueeze(0).expand(B, -1, -1)  # [B,m,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d338a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Model \n",
    "#--------------------------------------------------\n",
    "\n",
    "class PromptedTimmViT(nn.Module):\n",
    "    \"\"\"\n",
    "    Prompt injection into timm ViT:\n",
    "      tokens = [CLS | PROMPTS | PATCHES]\n",
    "    Works with timm VisionTransformer models (e.g., vit_base_patch16_224).\n",
    "    \"\"\"\n",
    "    def __init__(self, timm_vit: nn.Module, prompt: nn.Module):\n",
    "        super().__init__()\n",
    "        self.vit = timm_vit\n",
    "        self.prompt = prompt\n",
    "\n",
    "        # Ensure timm vit has these expected parts\n",
    "        assert hasattr(self.vit, \"patch_embed\")\n",
    "        assert hasattr(self.vit, \"pos_embed\")\n",
    "        assert hasattr(self.vit, \"cls_token\")\n",
    "        assert hasattr(self.vit, \"blocks\")\n",
    "        assert hasattr(self.vit, \"norm\")\n",
    "\n",
    "        self.embed_dim = self.vit.embed_dim\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # 1) Patch embedding (timm): [B, N, D]\n",
    "        x = self.vit.patch_embed(x)\n",
    "\n",
    "        # 2) CLS token: [B, 1, D]\n",
    "        cls = self.vit.cls_token.expand(B, -1, -1)\n",
    "\n",
    "        # 3) Prompt tokens: [B, M, D]\n",
    "        prompts = self.prompt(B)\n",
    "        if prompts.shape[-1] != self.embed_dim:\n",
    "            raise ValueError(f\"Prompt dim {prompts.shape[-1]} != ViT embed_dim {self.embed_dim}\")\n",
    "\n",
    "        # 4) Concat: [B, 1+M+N, D]\n",
    "        x = torch.cat([cls, prompts, x], dim=1)\n",
    "\n",
    "        # 5) Positional embedding handling\n",
    "        # timm pos_embed is usually [1, 1+N, D] (CLS + patches).\n",
    "        # We need [1, 1+M+N, D]. We'll insert M learnable prompt pos tokens.\n",
    "        pos = self._pos_embed_with_prompts(x)\n",
    "\n",
    "        x = x + pos\n",
    "        x = self.vit.pos_drop(x)\n",
    "\n",
    "        # 6) Transformer blocks\n",
    "        for blk in self.vit.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.vit.norm(x)\n",
    "\n",
    "        # 7) Use CLS output as feature: [B, D]\n",
    "        feat = x[:, 0]\n",
    "        return feat\n",
    "\n",
    "    def _pos_embed_with_prompts(self, x_tokens: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create positional embeddings for [CLS | PROMPTS | PATCHES].\n",
    "        \"\"\"\n",
    "        device = x_tokens.device\n",
    "        dtype = x_tokens.dtype\n",
    "\n",
    "        pos_base = self.vit.pos_embed.to(device=device, dtype=dtype)  # [1, 1+N, D]\n",
    "        base_len = pos_base.shape[1]\n",
    "        total_len = x_tokens.shape[1]\n",
    "        if total_len == base_len:\n",
    "            return pos_base\n",
    "\n",
    "        # total_len = 1 + M + N, base_len = 1 + N => M = total_len - base_len\n",
    "        M = total_len - base_len\n",
    "        assert M > 0\n",
    "\n",
    "        # create (or resize) learnable prompt position embeddings\n",
    "        if not hasattr(self, \"pos_embed_prompt\") or self.pos_embed_prompt.shape[1] != M:\n",
    "            self.pos_embed_prompt = nn.Parameter(torch.zeros(1, M, self.embed_dim, device=device, dtype=dtype))\n",
    "            nn.init.trunc_normal_(self.pos_embed_prompt, std=0.02)\n",
    "        else:\n",
    "            if self.pos_embed_prompt.device != device or self.pos_embed_prompt.dtype != dtype:\n",
    "                self.pos_embed_prompt = nn.Parameter(self.pos_embed_prompt.data.to(device=device, dtype=dtype))\n",
    "\n",
    "        cls_pos = pos_base[:, :1, :]   # [1,1,D]\n",
    "        patch_pos = pos_base[:, 1:, :] # [1,N,D]\n",
    "        pos = torch.cat([cls_pos, self.pos_embed_prompt, patch_pos], dim=1)  # [1,1+M+N,D]\n",
    "        return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Prototype memory + NCM logits\n",
    "# ---------------------------\n",
    "class PrototypeMemory(nn.Module):\n",
    "    def __init__(self, feat_dim: int):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.register_buffer(\"prototypes\", torch.empty(0, feat_dim))\n",
    "        self.register_buffer(\"counts\", torch.empty(0))\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return int(self.prototypes.shape[0])\n",
    "\n",
    "    def ensure_size(self, C: int, device: torch.device):\n",
    "        if self.num_classes >= C:\n",
    "            return\n",
    "        old = self.num_classes\n",
    "        pad_proto = torch.zeros(C - old, self.feat_dim, device=device)\n",
    "        pad_cnt = torch.zeros(C - old, device=device)\n",
    "        if old == 0:\n",
    "            self.prototypes = pad_proto\n",
    "            self.counts = pad_cnt\n",
    "        else:\n",
    "            self.prototypes = torch.cat([self.prototypes.to(device), pad_proto], dim=0)\n",
    "            self.counts = torch.cat([self.counts.to(device), pad_cnt], dim=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_from_batch(self, feats: torch.Tensor, labels: torch.Tensor):\n",
    "        device = feats.device\n",
    "        max_label = int(labels.max().item())\n",
    "        self.ensure_size(max_label + 1, device)\n",
    "\n",
    "        for c in labels.unique():\n",
    "            c = int(c.item())\n",
    "            idx = labels == c\n",
    "            f_c = feats[idx]\n",
    "            k = f_c.shape[0]\n",
    "            if k == 0:\n",
    "                continue\n",
    "            mu_old = self.prototypes[c]\n",
    "            n_old = self.counts[c].clamp(min=0.0)\n",
    "            mu_new = (n_old * mu_old + f_c.sum(dim=0)) / (n_old + float(k))\n",
    "            self.prototypes[c] = mu_new\n",
    "            self.counts[c] = n_old + float(k)\n",
    "\n",
    "    def logits_ncm(self, feats: torch.Tensor, tau: float = 1.0, normalize: bool = True) -> torch.Tensor:\n",
    "        if self.num_classes == 0:\n",
    "            raise RuntimeError(\"Empty prototype memory.\")\n",
    "        proto = self.prototypes.to(feats.device)\n",
    "        h = feats\n",
    "        if normalize:\n",
    "            proto = l2_normalize(proto, dim=-1)\n",
    "            h = l2_normalize(h, dim=-1)\n",
    "        d2 = torch.cdist(h, proto, p=2) ** 2\n",
    "        return -d2 / tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2353381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Losses\n",
    "# ---------------------------\n",
    "def proto_alignment_loss(feats: torch.Tensor, labels: torch.Tensor, proto_mem: PrototypeMemory) -> torch.Tensor:\n",
    "    proto = proto_mem.prototypes.to(feats.device)\n",
    "    mu = proto[labels]\n",
    "    feats_n = l2_normalize(feats, dim=-1)\n",
    "    mu_n = l2_normalize(mu, dim=-1)\n",
    "    return ((feats_n - mu_n) ** 2).sum(dim=-1).mean()\n",
    "\n",
    "\n",
    "def kd_loss_logits(logits_teacher: torch.Tensor, logits_student: torch.Tensor, T: float = 2.0) -> torch.Tensor:\n",
    "    p_t = F.softmax(logits_teacher / T, dim=-1)\n",
    "    log_p_s = F.log_softmax(logits_student / T, dim=-1)\n",
    "    return F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T * T)\n",
    "\n",
    "\n",
    "def domain_shift_loss(feats_old: torch.Tensor, feats_new: torch.Tensor) -> torch.Tensor:\n",
    "    mu_old = l2_normalize(feats_old.mean(dim=0), dim=-1)\n",
    "    mu_new = l2_normalize(feats_new.mean(dim=0), dim=-1)\n",
    "    return ((mu_old - mu_new) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cebc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# System wrapper\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class FSCILConfig:\n",
    "    # -----------------------\n",
    "    # Backbone (timm ViT)\n",
    "    # -----------------------\n",
    "    vit_name: str = \"vit_base_patch16_224\"\n",
    "    pretrained: bool = True\n",
    "\n",
    "    # timm vit_base_patch16_224 expects 224x224 and outputs 768-dim features\n",
    "    img_size: int = 224\n",
    "    patch_size: int = 16          # fixed by model name (B/16)\n",
    "    feat_dim: int = 768           # ViT-Base embedding dim\n",
    "    num_prompts: int = 10\n",
    "\n",
    "    # -----------------------\n",
    "    # Optimization\n",
    "    # -----------------------\n",
    "    base_epochs: int = 10\n",
    "    inc_epochs: int = 20\n",
    "    lr_base: float = 1e-4\n",
    "    lr_inc: float = 5e-5\n",
    "    weight_decay: float = 0.05\n",
    "\n",
    "    batch_size: int = 64\n",
    "\n",
    "    # -----------------------\n",
    "    # FSCIL protocol (MiniImageNet/CIFAR100 style)\n",
    "    # -----------------------\n",
    "    base_classes: int = 60\n",
    "    ways_per_session: int = 5\n",
    "    shots_per_class: int = 5\n",
    "    replay_max_per_class: int = 20\n",
    "\n",
    "    # -----------------------\n",
    "    # Loss / EMA\n",
    "    # -----------------------\n",
    "    tau: float = 1.0\n",
    "    kd_T: float = 2.0\n",
    "    ema_alpha: float = 0.999\n",
    "\n",
    "    lam_proto: float = 1.0\n",
    "    lam_kd: float = 1.0\n",
    "    lam_domain: float = 0.5\n",
    "\n",
    "    seed: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8673c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class FSCILSystem(nn.Module):\n",
    "    def __init__(self, cfg: FSCILConfig, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "\n",
    "        # IMPORTANT: cfg.feat_dim must match timm vit embed_dim (vit_base_patch16_224 -> 768)\n",
    "        # If cfg.feat_dim is not 768, set it to vit_template.embed_dim after model creation.\n",
    "\n",
    "        vit_template = timm.create_model(\n",
    "            cfg.vit_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0  # feature extractor\n",
    "        ).to(device)\n",
    "\n",
    "        # Ensure cfg.feat_dim matches actual ViT dim\n",
    "        if cfg.feat_dim != vit_template.embed_dim:\n",
    "            raise ValueError(f\"cfg.feat_dim={cfg.feat_dim} but vit.embed_dim={vit_template.embed_dim}. \"\n",
    "                             f\"Set cfg.feat_dim={vit_template.embed_dim} (768 for vit_base).\")\n",
    "\n",
    "        # base prompt (persistent)\n",
    "        self.base_prompt = PromptModule(cfg.num_prompts, cfg.feat_dim).to(device)\n",
    "\n",
    "        # stable = EMA teacher (persistent)\n",
    "        self.stable = PromptedTimmViT(copy.deepcopy(vit_template), self.base_prompt).to(device)\n",
    "        set_requires_grad(self.stable, False)  # stable frozen (EMA only)\n",
    "\n",
    "        # plastic/session prompt are created per session (temporary)\n",
    "        self.plastic: Optional[PromptedTimmViT] = None\n",
    "        self.session_prompt: Optional[PromptModule] = None\n",
    "\n",
    "        # prototype memory (persistent)\n",
    "        self.proto_mem = PrototypeMemory(cfg.feat_dim).to(device)\n",
    "\n",
    "        # keep vit template for plastic recreation\n",
    "        self._vit_template = vit_template\n",
    "\n",
    "    def new_plastic_for_session(self):\n",
    "        cfg = self.cfg\n",
    "\n",
    "        # clone ViT and init from stable vit weights\n",
    "        vit = copy.deepcopy(self._vit_template).to(self.device)\n",
    "\n",
    "        # stable.vit is the timm ViT inside PromptedTimmViT\n",
    "        vit.load_state_dict(self.stable.vit.state_dict(), strict=True)\n",
    "\n",
    "        # session prompt initialized from base prompt (+ noise)\n",
    "        P_base = self.base_prompt.prompts.detach()\n",
    "        sp = PromptModule(cfg.num_prompts, cfg.feat_dim).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            sp.prompts.copy_(P_base + 0.01 * torch.randn_like(P_base))\n",
    "\n",
    "        self.session_prompt = sp\n",
    "        self.plastic = PromptedTimmViT(vit, self.session_prompt).to(self.device)\n",
    "        set_requires_grad(self.plastic, True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def build_prototypes(self, loader: DataLoader):\n",
    "        self.stable.eval()\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            h = self.stable(x)  # [B, 768]\n",
    "            self.proto_mem.update_from_batch(h, y)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.stable.eval()\n",
    "        h = self.stable(x.to(self.device))\n",
    "        logits = self.proto_mem.logits_ncm(h, tau=self.cfg.tau, normalize=True)\n",
    "        return logits.argmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training / Evaluation\n",
    "# ---------------------------\n",
    "def accuracy(model: FSCILSystem, loader: DataLoader) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(model.device), y.to(model.device)\n",
    "        pred = model.predict(x)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(total, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from dataclasses import asdict\n",
    "\n",
    "def save_checkpoint(\n",
    "    model: \"FSCILSystem\",\n",
    "    path: str,\n",
    "    session_id: int,\n",
    "    replay_buffer: Optional[object] = None,  # your ReplayBuffer instance\n",
    "    extra: Optional[dict] = None,\n",
    "):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "\n",
    "    ckpt = {\n",
    "        \"session_id\": session_id,\n",
    "        \"cfg\": asdict(model.cfg) if hasattr(model, \"cfg\") else None,\n",
    "\n",
    "        # Persistent model parts\n",
    "        \"stable\": model.stable.state_dict(),\n",
    "        \"base_prompt\": model.base_prompt.state_dict(),\n",
    "\n",
    "        # Prototype memory\n",
    "        \"proto_prototypes\": model.proto_mem.prototypes.detach().cpu(),\n",
    "        \"proto_counts\": model.proto_mem.counts.detach().cpu(),\n",
    "\n",
    "        # Optional: base linear head (only used in base stage)\n",
    "        \"base_head\": getattr(train_base, \"head\", None).state_dict() if hasattr(train_base, \"head\") else None,\n",
    "\n",
    "        # Optional: replay buffer indices\n",
    "        \"replay\": replay_buffer.storage if replay_buffer is not None else None,\n",
    "\n",
    "        # Optional: RNG for exact reproducibility\n",
    "        \"rng_torch\": torch.get_rng_state(),\n",
    "        \"rng_cuda\": torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,\n",
    "    }\n",
    "\n",
    "    if extra is not None:\n",
    "        ckpt[\"extra\"] = extra\n",
    "\n",
    "    torch.save(ckpt, path)\n",
    "    print(f\"[CKPT] Saved -> {path}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    model: \"FSCILSystem\",\n",
    "    path: str,\n",
    "    replay_buffer: Optional[object] = None,\n",
    "    map_location: str = \"cpu\",\n",
    "):\n",
    "    ckpt = torch.load(path, map_location=map_location)\n",
    "\n",
    "    model.stable.load_state_dict(ckpt[\"stable\"])\n",
    "    model.base_prompt.load_state_dict(ckpt[\"base_prompt\"])\n",
    "\n",
    "    # Restore prototypes\n",
    "    with torch.no_grad():\n",
    "        model.proto_mem.prototypes = ckpt[\"proto_prototypes\"].to(model.device)\n",
    "        model.proto_mem.counts = ckpt[\"proto_counts\"].to(model.device)\n",
    "\n",
    "    # Restore base head if present\n",
    "    if ckpt.get(\"base_head\", None) is not None:\n",
    "        # You must create the head with correct out_features before loading\n",
    "        C = ckpt[\"base_head\"][\"weight\"].shape[0]\n",
    "        train_base.head = nn.Linear(model.cfg.feat_dim, C).to(model.device)\n",
    "        train_base.head.load_state_dict(ckpt[\"base_head\"])\n",
    "\n",
    "    # Restore replay buffer if provided\n",
    "    if replay_buffer is not None and ckpt.get(\"replay\", None) is not None:\n",
    "        replay_buffer.storage = ckpt[\"replay\"]\n",
    "\n",
    "    # Restore RNG (optional)\n",
    "    if ckpt.get(\"rng_torch\", None) is not None:\n",
    "        torch.set_rng_state(ckpt[\"rng_torch\"])\n",
    "    if torch.cuda.is_available() and ckpt.get(\"rng_cuda\", None) is not None:\n",
    "        torch.cuda.set_rng_state_all(ckpt[\"rng_cuda\"])\n",
    "\n",
    "    session_id = ckpt.get(\"session_id\", 0)\n",
    "    print(f\"[CKPT] Loaded <- {path} | session_id={session_id} | prototypes={model.proto_mem.num_classes}\")\n",
    "    return session_id, ckpt.get(\"extra\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a69f55",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_preds(\n",
    "    model: FSCILSystem,\n",
    "    loader: DataLoader,\n",
    "    allowed_max_class: int,     # evaluate only y < allowed_max_class\n",
    "):\n",
    "    model.stable.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        # filter by seen classes\n",
    "        mask = (y < allowed_max_class)\n",
    "        if mask.sum().item() == 0:\n",
    "            continue\n",
    "\n",
    "        x = x[mask].to(model.device)\n",
    "        y = y[mask].to(model.device)\n",
    "\n",
    "        h = model.stable(x)\n",
    "        logits = model.proto_mem.logits_ncm(h, tau=model.cfg.tau, normalize=True)\n",
    "        pred = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true.extend(y.cpu().tolist())\n",
    "        y_pred.extend(pred.cpu().tolist())\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_base(model: FSCILSystem, test_loader: DataLoader, class_names=None):\n",
    "    base_C = model.cfg.base_classes\n",
    "    y_true, y_pred = collect_preds(model, test_loader, allowed_max_class=base_C)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n========== BASE REPORT (classes 0 to {base_C-1}) ==========\")\n",
    "    print(f\"[BASE] Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    # optional names: must match only base classes\n",
    "    names = None\n",
    "    if class_names is not None:\n",
    "        names = class_names[:base_C]\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=names, digits=4))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_session(model: FSCILSystem, test_loader: DataLoader, session_id: int, class_names=None):\n",
    "    seen_C = model.cfg.base_classes + session_id * model.cfg.ways_per_session\n",
    "    y_true, y_pred = collect_preds(model, test_loader, allowed_max_class=seen_C)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n========== SESSION {session_id} REPORT (classes 0 to {seen_C-1}) ==========\")\n",
    "    print(f\"[SESSION {session_id}] Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    names = None\n",
    "    if class_names is not None:\n",
    "        names = class_names[:seen_C]\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=names, digits=4))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_final(model: FSCILSystem, test_loader: DataLoader, total_classes: int, class_names=None):\n",
    "    y_true, y_pred = collect_preds(model, test_loader, allowed_max_class=total_classes)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n========== FINAL REPORT (classes 0 to {total_classes-1}) ==========\")\n",
    "    print(f\"[FINAL] Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    names = class_names if class_names is not None else None\n",
    "    print(classification_report(y_true, y_pred, target_names=names, digits=4))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e07b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_log = {\"base\": None, \"sessions\": [], \"final\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a881239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training Base \n",
    "# ---------------------------\n",
    "\n",
    "def evaluate_stable_accuracy(model: FSCILSystem, loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Base-stage evaluation using stable stream + temporary linear head.\n",
    "    FILTERED: evaluates only base classes [0 .. base_classes-1].\n",
    "    \"\"\"\n",
    "    model.stable.eval()\n",
    "    head = getattr(train_base, \"head\", None)\n",
    "    if head is None:\n",
    "        return 0.0\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    base_C = model.cfg.base_classes  # e.g., 60\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # ---- FILTER: keep only base-class samples ----\n",
    "            mask = (y < base_C)\n",
    "            if mask.sum().item() == 0:\n",
    "                continue\n",
    "\n",
    "            x = x[mask].to(model.device)\n",
    "            y = y[mask].to(model.device)\n",
    "\n",
    "            h = model.stable(x)  # [B, D]\n",
    "            logits = head(l2_normalize(h))\n",
    "            pred = logits.argmax(dim=-1)\n",
    "\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.numel()\n",
    "\n",
    "    return correct / max(total, 1)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Training Base (tqdm + val + early stopping)\n",
    "# ---------------------------\n",
    "def train_base(\n",
    "    model: FSCILSystem,\n",
    "    base_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    patience: int = 35,\n",
    "    min_delta: float = 1e-4,\n",
    "):\n",
    "    cfg = model.cfg\n",
    "    device = model.device\n",
    "\n",
    "    # train a temporary plastic that uses BASE prompt (same as stable prompt)\n",
    "    plastic = PromptedTimmViT(\n",
    "        copy.deepcopy(model._vit_template).to(device),\n",
    "        model.base_prompt\n",
    "    ).to(device)\n",
    "    set_requires_grad(plastic, True)\n",
    "\n",
    "    # stable is EMA-updated only\n",
    "    model.stable.eval()\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        plastic.parameters(),\n",
    "        lr=cfg.lr_base,\n",
    "        weight_decay=cfg.weight_decay\n",
    "    )\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "\n",
    "    for ep in range(cfg.base_epochs):\n",
    "        plastic.train()\n",
    "\n",
    "        epoch_bar = tqdm(\n",
    "            base_loader,\n",
    "            desc=f\"[Base] Epoch {ep+1}/{cfg.base_epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for x, y in epoch_bar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            h = plastic(x)  # [B, D]\n",
    "\n",
    "            # temporary linear head for base training only\n",
    "            if (not hasattr(train_base, \"head\")) or (train_base.head.out_features <= int(y.max().item())):\n",
    "                C = int(y.max().item()) + 1\n",
    "                train_base.head = nn.Linear(cfg.feat_dim, C).to(device)\n",
    "                train_base.head_opt = torch.optim.AdamW(\n",
    "                    train_base.head.parameters(),\n",
    "                    lr=cfg.lr_base,\n",
    "                    weight_decay=cfg.weight_decay\n",
    "                )\n",
    "\n",
    "            logits = train_base.head(l2_normalize(h))\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            train_base.head_opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_base.head_opt.step()\n",
    "\n",
    "            # EMA: stable <- plastic (vit weights only)\n",
    "            ema_update(model.stable.vit, plastic.vit, alpha=cfg.ema_alpha)\n",
    "\n",
    "            epoch_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        epoch_bar.close()\n",
    "\n",
    "        # -----------------------\n",
    "        # Validation after epoch\n",
    "        # -----------------------\n",
    "        val_acc = evaluate_stable_accuracy(model, val_loader)\n",
    "        print(f\"[Base] Epoch {ep+1}: val_acc={val_acc*100:.2f}%\")\n",
    "\n",
    "        # -----------------------\n",
    "        # Early stopping logic\n",
    "        # -----------------------\n",
    "        if val_acc > best_acc + min_delta:\n",
    "            best_acc = val_acc\n",
    "            no_improve = 0\n",
    "\n",
    "            # Save best stable model weights (+ head if you want)\n",
    "            best_state = {\n",
    "                \"stable\": copy.deepcopy(model.stable.state_dict()),\n",
    "                \"head\": copy.deepcopy(train_base.head.state_dict()),\n",
    "            }\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"[Base] Early stopping triggered at epoch {ep+1}. Best val_acc={best_acc*100:.2f}%\")\n",
    "                break\n",
    "    \n",
    "\n",
    "    \n",
    "    # -----------------------\n",
    "    # Restore best weights\n",
    "    # -----------------------\n",
    "    if best_state is not None:\n",
    "        model.stable.load_state_dict(best_state[\"stable\"])\n",
    "        train_base.head.load_state_dict(best_state[\"head\"])\n",
    "        print(f\"[Base] Restored best model. Best val_acc={best_acc*100:.2f}%\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Build prototypes using stable (and base prompt)\n",
    "    # -----------------------\n",
    "    model.proto_mem.prototypes = model.proto_mem.prototypes[:0]\n",
    "    model.proto_mem.counts = model.proto_mem.counts[:0]\n",
    "    model.build_prototypes(base_loader)\n",
    "\n",
    "    save_checkpoint(\n",
    "        model,\n",
    "        path=\"checkpoints/base.ckpt\",\n",
    "        session_id=0,\n",
    "        replay_buffer=None  # if you use replay during base, pass it\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"[Base] prototypes built: {model.proto_mem.num_classes}\")\n",
    "\n",
    "    acc_log[\"base\"] = report_base(model, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59974031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training Incremental\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def train_incremental(\n",
    "    model: FSCILSystem,\n",
    "    new_loader: DataLoader,\n",
    "    replay_loader: Optional[DataLoader],\n",
    "    session_id: int,\n",
    "    replay_buffer=None\n",
    "):\n",
    "    cfg = model.cfg\n",
    "    device = model.device\n",
    "\n",
    "    model.new_plastic_for_session()\n",
    "    assert model.plastic is not None\n",
    "    plastic = model.plastic\n",
    "\n",
    "    model.stable.eval()\n",
    "    plastic.train()\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        plastic.parameters(),\n",
    "        lr=cfg.lr_inc,\n",
    "        weight_decay=cfg.weight_decay\n",
    "    )\n",
    "\n",
    "    replay_iter = iter(replay_loader) if replay_loader is not None else None\n",
    "\n",
    "    for ep in range(cfg.inc_epochs):\n",
    "\n",
    "        epoch_bar = tqdm(\n",
    "            new_loader,\n",
    "            desc=f\"[Inc S{session_id}] Epoch {ep+1}/{cfg.inc_epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for x_new, y_new in epoch_bar:\n",
    "            x_new, y_new = x_new.to(device), y_new.to(device)\n",
    "\n",
    "\n",
    "            # IMPORTANT: allocate prototype slots for new classes\n",
    "            model.proto_mem.ensure_size(int(y_new.max().item()) + 1, device=device)\n",
    "\n",
    "            # ---- new-class forward (plastic) ----\n",
    "            h_new = plastic(x_new)\n",
    "            logits_new = model.proto_mem.logits_ncm(\n",
    "                h_new, tau=cfg.tau, normalize=True\n",
    "            )\n",
    "\n",
    "            loss_cls = F.cross_entropy(logits_new, y_new)\n",
    "            loss_proto = proto_alignment_loss(h_new, y_new, model.proto_mem)\n",
    "\n",
    "            # ---- old-class forward (stable teacher + plastic student) ----\n",
    "            loss_kd = torch.tensor(0.0, device=device)\n",
    "            loss_dom = torch.tensor(0.0, device=device)\n",
    "\n",
    "            if replay_iter is not None:\n",
    "                try:\n",
    "                    x_old, y_old = next(replay_iter)\n",
    "                except StopIteration:\n",
    "                    replay_iter = iter(replay_loader)\n",
    "                    x_old, y_old = next(replay_iter)\n",
    "\n",
    "                x_old, y_old = x_old.to(device), y_old.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    h_old_s = model.stable(x_old)\n",
    "                    logits_old_s = model.proto_mem.logits_ncm(\n",
    "                        h_old_s, tau=cfg.tau, normalize=True\n",
    "                    )\n",
    "\n",
    "                h_old_p = plastic(x_old)\n",
    "                logits_old_p = model.proto_mem.logits_ncm(\n",
    "                    h_old_p, tau=cfg.tau, normalize=True\n",
    "                )\n",
    "\n",
    "                loss_kd = kd_loss_logits(\n",
    "                    logits_old_s, logits_old_p, T=cfg.kd_T\n",
    "                )\n",
    "\n",
    "                loss_dom = domain_shift_loss(h_old_s, h_new)\n",
    "\n",
    "            # ---- total loss ----\n",
    "            loss = (\n",
    "                loss_cls\n",
    "                + cfg.lam_proto * loss_proto\n",
    "                + cfg.lam_kd * loss_kd\n",
    "                + cfg.lam_domain * loss_dom\n",
    "            )\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # EMA merge plastic -> stable (ViT weights only)\n",
    "            ema_update(\n",
    "                model.stable.vit,\n",
    "                plastic.vit,\n",
    "                alpha=cfg.ema_alpha\n",
    "            )\n",
    "\n",
    "            # Update prototypes for new classes\n",
    "            with torch.no_grad():\n",
    "                model.proto_mem.update_from_batch(\n",
    "                    h_new.detach(),\n",
    "                    y_new.detach()\n",
    "                )\n",
    "\n",
    "            # update tqdm bar\n",
    "            epoch_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        epoch_bar.close()\n",
    "\n",
    "        print(\n",
    "            f\"[Inc S{session_id}] Epoch {ep+1}/{cfg.inc_epochs} completed | \"\n",
    "            f\"last_loss={loss.item():.4f}\"\n",
    "        )\n",
    "\n",
    "        \n",
    "    # discard plastic/session prompt\n",
    "    model.plastic = None\n",
    "    model.session_prompt = None\n",
    "\n",
    "    save_checkpoint(\n",
    "        model,\n",
    "        path=f\"checkpoints/session_{session_id}.ckpt\",\n",
    "        session_id=session_id,\n",
    "        replay_buffer=replay_buffer\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[Inc] session {session_id} done. \"\n",
    "        f\"Total prototypes now: {model.proto_mem.num_classes}\"\n",
    "    )\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87293918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Main: CIFAR-100 FSCIL\n",
    "# ---------------------------\n",
    "def main_cifar100(cfg: FSCILConfig):\n",
    "    seed_all(cfg.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # transforms (match cfg.img_size)\n",
    "    tf_train = T.Compose([\n",
    "        T.Resize((cfg.img_size, cfg.img_size)),\n",
    "        T.RandomCrop(cfg.img_size, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    tf_test = T.Compose([\n",
    "        T.Resize((cfg.img_size, cfg.img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=tf_train)\n",
    "    testset  = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=tf_test)\n",
    "\n",
    "    train_targets = list(trainset.targets)\n",
    "    test_targets = list(testset.targets)\n",
    "\n",
    "    base_cls, inc_sessions = make_fscil_splits(\n",
    "        targets=train_targets,\n",
    "        base_classes=cfg.base_classes,\n",
    "        ways_per_session=cfg.ways_per_session,\n",
    "        shots_per_class=cfg.shots_per_class,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "\n",
    "    # Build loaders\n",
    "    print(base_cls)\n",
    "    base_idx = indices_for_classes(train_targets, base_cls)\n",
    "    \n",
    "    base_loader = DataLoader(Subset(trainset, base_idx), batch_size=cfg.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Test loader: we evaluate on full test set (all classes)\n",
    "    test_loader = DataLoader(testset, batch_size=cfg.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Replay buffer\n",
    "    replay = ReplayBuffer(max_per_class=cfg.replay_max_per_class, seed=cfg.seed)\n",
    "\n",
    "    # System\n",
    "    model = FSCILSystem(cfg, device=device).to(device)\n",
    "\n",
    "    print(\"\\n=== BASE TRAINING ===\")\n",
    "    train_base(model, base_loader,test_loader)\n",
    "\n",
    "    # Add some base exemplars to replay\n",
    "    # (sample few indices from base set for replay memory)\n",
    "    replay.add_indices(train_targets, random.sample(base_idx, min(len(base_idx), cfg.replay_max_per_class * len(base_cls))))\n",
    "\n",
    "    acc0 = accuracy(model, test_loader)\n",
    "    print(f\"[Eval] After base: Acc(all test classes) = {acc0*100:.2f}%\")\n",
    "\n",
    "    # Incremental sessions\n",
    "    for s, sess_classes in enumerate(inc_sessions, start=1):\n",
    "        print(f\"\\n=== INCREMENTAL SESSION {s}/{len(inc_sessions)} | classes={sess_classes} ===\")\n",
    "\n",
    "        # new few-shot indices (shots per class)\n",
    "        new_idx = fewshot_indices_for_classes(train_targets, sess_classes, cfg.shots_per_class, seed=cfg.seed + s)\n",
    "        new_loader = DataLoader(Subset(trainset, new_idx), batch_size=min(cfg.batch_size, len(new_idx)), shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # replay loader from buffer (old classes)\n",
    "        replay_idx = replay.all_indices()\n",
    "        replay_loader = None\n",
    "        if len(replay_idx) > 0:\n",
    "            replay_loader = DataLoader(Subset(trainset, replay_idx), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # Train session\n",
    "        train_incremental(model, new_loader, replay_loader, session_id=s, replay_buffer=replay)\n",
    "\n",
    "        # Update replay with new indices\n",
    "        replay.add_indices(train_targets, new_idx)\n",
    "\n",
    "        acc = accuracy(model, test_loader)\n",
    "        acc_log[\"sessions\"].append(report_session(model, test_loader, s))\n",
    "        print(f\"[Eval] After session {s}: Acc(all test classes) = {acc*100:.2f}%\")\n",
    "    \n",
    "    acc_log[\"final\"] = report_final(model, test_loader, total_classes=100)\n",
    "\n",
    "    print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cfg = FSCILConfig(\n",
    "        vit_name=\"vit_small_patch16_224\",\n",
    "        pretrained=True,\n",
    "\n",
    "        img_size=224,\n",
    "        patch_size=16,   # fixed by vit\n",
    "        feat_dim=384,    # fixed by ViT\n",
    "        num_prompts=10,\n",
    "\n",
    "        base_epochs=35,\n",
    "        inc_epochs=20,\n",
    "        lr_base=1e-4,\n",
    "        lr_inc=5e-5,\n",
    "        weight_decay=0.05,\n",
    "\n",
    "        base_classes=60,\n",
    "        ways_per_session=5,\n",
    "        shots_per_class=5,\n",
    "        replay_max_per_class=20,\n",
    "        batch_size=64,   # 128 may OOM on some GPUs with ViT-B/16\n",
    "\n",
    "        tau=1.0,\n",
    "        kd_T=2.0,\n",
    "        ema_alpha=0.999,\n",
    "        lam_proto=1.0,\n",
    "        lam_kd=1.0,\n",
    "        lam_domain=0.5,\n",
    "\n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    main_cifar100(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd343cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e633700",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"acc_log.txt\", \"w\") as f:\n",
    "    for item in acc_log:\n",
    "        f.write(str(item) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiface_generate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
