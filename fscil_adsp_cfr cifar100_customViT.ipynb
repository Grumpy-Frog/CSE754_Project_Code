{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fscil_adsp_cfr_full.py\n",
    "# Fully functional FSCIL (ADSP-CFR style) reference implementation.\n",
    "# Runs end-to-end on CIFAR-100 by default.\n",
    "#\n",
    "# Key modules:\n",
    "# - Plastic stream (trainable backbone + session prompt)\n",
    "# - Stable stream (EMA backbone + base prompt) as teacher/memory\n",
    "# - Prototype Memory + NCM classifier\n",
    "# - Losses: CE + proto + KD + domain\n",
    "#\n",
    "# NOTE: This is a research-grade reference implementation (not SOTA optimized).\n",
    "# It is designed to be clear, correct, and runnable.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aea29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "def seed_all(seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4381a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:\n",
    "    return x / (x.norm(p=2, dim=dim, keepdim=True) + eps)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher: nn.Module, student: nn.Module, alpha: float):\n",
    "    \"\"\"teacher = alpha*teacher + (1-alpha)*student\"\"\"\n",
    "    t_params = dict(teacher.named_parameters())\n",
    "    for name, p_s in student.named_parameters():\n",
    "        p_t = t_params[name]\n",
    "        p_t.data.mul_(alpha).add_(p_s.data, alpha=(1.0 - alpha))\n",
    "\n",
    "\n",
    "def set_requires_grad(module: nn.Module, flag: bool):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b52d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Dataset: MiniImageNet (optional)\n",
    "# Folder structure expected:\n",
    "# root/\n",
    "#   train/class_x/xxx.png ...\n",
    "#   test/class_x/xxx.png ...\n",
    "#   val/class_x/xxx.png ...\n",
    "# ---------------------------\n",
    "class MiniImageNetFolder(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root_split: str, transform=None):\n",
    "        super().__init__(root=root_split, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfafd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Split FSCIL sessions\n",
    "# ---------------------------\n",
    "def make_fscil_splits(\n",
    "    targets: List[int],\n",
    "    base_classes: int = 60,\n",
    "    ways_per_session: int = 5,\n",
    "    shots_per_class: int = 5,\n",
    "    seed: int = 0,\n",
    ") -> Tuple[List[int], List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      base_class_ids: list of class ids in base session\n",
    "      inc_sessions: list of sessions, each session is list of class ids\n",
    "    \"\"\"\n",
    "    seed_all(seed)\n",
    "    classes = sorted(list(set(targets)))\n",
    "    assert len(classes) >= base_classes, \"Not enough classes.\"\n",
    "\n",
    "    random.shuffle(classes)\n",
    "    base_cls = classes[:base_classes]\n",
    "    remaining = classes[base_classes:]\n",
    "\n",
    "    inc_sessions = []\n",
    "    for i in range(0, len(remaining), ways_per_session):\n",
    "        sess = remaining[i:i + ways_per_session]\n",
    "        if len(sess) == ways_per_session:\n",
    "            inc_sessions.append(sess)\n",
    "\n",
    "    return base_cls, inc_sessions\n",
    "\n",
    "\n",
    "def indices_for_classes(targets: List[int], class_ids: List[int]) -> List[int]:\n",
    "    s = set(class_ids)\n",
    "    return [i for i, y in enumerate(targets) if y in s]\n",
    "\n",
    "\n",
    "def fewshot_indices_for_classes(\n",
    "    targets: List[int],\n",
    "    class_ids: List[int],\n",
    "    shots_per_class: int,\n",
    "    seed: int = 0\n",
    ") -> List[int]:\n",
    "    seed_all(seed)\n",
    "    idxs = []\n",
    "    for c in class_ids:\n",
    "        all_idx = [i for i, y in enumerate(targets) if y == c]\n",
    "        random.shuffle(all_idx)\n",
    "        idxs.extend(all_idx[:shots_per_class])\n",
    "    return idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83136bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Memory buffer for replay\n",
    "# ---------------------------\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_per_class: int = 20, seed: int = 0):\n",
    "        self.max_per_class = max_per_class\n",
    "        self.seed = seed\n",
    "        self.storage: Dict[int, List[int]] = {}  # class_id -> list of dataset indices\n",
    "\n",
    "    def add_indices(self, targets: List[int], new_indices: List[int]):\n",
    "        # store up to max_per_class per class\n",
    "        for idx in new_indices:\n",
    "            c = targets[idx]\n",
    "            if c not in self.storage:\n",
    "                self.storage[c] = []\n",
    "            self.storage[c].append(idx)\n",
    "\n",
    "        # trim\n",
    "        seed_all(self.seed)\n",
    "        for c in list(self.storage.keys()):\n",
    "            lst = self.storage[c]\n",
    "            random.shuffle(lst)\n",
    "            self.storage[c] = lst[: self.max_per_class]\n",
    "\n",
    "    def all_indices(self) -> List[int]:\n",
    "        out = []\n",
    "        for c, lst in self.storage.items():\n",
    "            out.extend(lst)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Prompt module (learnable tokens)\n",
    "# ---------------------------\n",
    "class PromptModule(nn.Module):\n",
    "    \"\"\"\n",
    "    prompts: [m, D]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_prompts: int, dim: int, init_std: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.prompts = nn.Parameter(torch.randn(num_prompts, dim) * init_std)\n",
    "\n",
    "    def forward(self, B: int) -> torch.Tensor:\n",
    "        return self.prompts.unsqueeze(0).expand(B, -1, -1)  # [B,m,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# A simple ViT (functional, no external libs)\n",
    "# Prompt injection is exact: [CLS | PROMPTS | PATCHES]\n",
    "# ---------------------------\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size: int, patch_size: int, in_chans: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        assert img_size % patch_size == 0\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid = img_size // patch_size\n",
    "        self.num_patches = self.grid * self.grid\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B,C,H,W] -> [B, N, D]\n",
    "        x = self.proj(x)                # [B,D,grid,grid]\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B,N,D]\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size: int = 32,\n",
    "        patch_size: int = 4,\n",
    "        in_chans: int = 3,\n",
    "        embed_dim: int = 256,\n",
    "        depth: int = 6,\n",
    "        num_heads: int = 8,\n",
    "        mlp_ratio: float = 4.0,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "\n",
    "        # NOTE: pos_embed must match token count: 1 + M + N (but M changes by prompt count)\n",
    "        # We'll handle pos_embed in PromptedViT wrapper (since prompts are external).\n",
    "        self.pos_drop = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=int(embed_dim * mlp_ratio),\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "\n",
    "    def forward_tokens(self, x_tokens: torch.Tensor, pos_embed: torch.Tensor) -> torch.Tensor:\n",
    "        # x_tokens: [B, 1+M+N, D]\n",
    "        x_tokens = x_tokens + pos_embed\n",
    "        x_tokens = self.pos_drop(x_tokens)\n",
    "        x_tokens = self.encoder(x_tokens)\n",
    "        x_tokens = self.norm(x_tokens)\n",
    "        return x_tokens\n",
    "\n",
    "    def patch_tokens(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.patch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d338a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptedViT(nn.Module):\n",
    "    \"\"\"\n",
    "    Exact prompt injection:\n",
    "      tokens = [CLS | PROMPTS | PATCHES]\n",
    "    \"\"\"\n",
    "    def __init__(self, vit: SimpleViT, prompt: PromptModule, img_size: int, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.vit = vit\n",
    "        self.prompt = prompt\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # pos embed for max tokens will be built dynamically at runtime (safe).\n",
    "        # We register a parameter for base length = 1 + N (no prompts) and extend if needed.\n",
    "        N = vit.patch.num_patches\n",
    "        self.pos_embed_base = nn.Parameter(torch.zeros(1, 1 + N, vit.embed_dim))\n",
    "        nn.init.trunc_normal_(self.pos_embed_base, std=0.02)\n",
    "\n",
    "    def _build_pos_embed(self, total_tokens: int) -> torch.Tensor:\n",
    "        base = self.pos_embed_base                      # [1, 1+N, D]\n",
    "        base_len = base.shape[1]\n",
    "        D = base.shape[2]\n",
    "        device = base.device\n",
    "        dtype = base.dtype\n",
    "\n",
    "        if total_tokens == base_len:\n",
    "            return base\n",
    "\n",
    "        # total_tokens = 1 + M + N, base_len = 1 + N  => M = total_tokens - base_len\n",
    "        M = total_tokens - base_len\n",
    "        assert M > 0\n",
    "\n",
    "        # Create or resize prompt positional embeddings on SAME device/dtype\n",
    "        if not hasattr(self, \"pos_embed_prompt\") or self.pos_embed_prompt.shape[1] != M:\n",
    "            self.pos_embed_prompt = nn.Parameter(\n",
    "                torch.zeros(1, M, D, device=device, dtype=dtype)\n",
    "            )\n",
    "            nn.init.trunc_normal_(self.pos_embed_prompt, std=0.02)\n",
    "        else:\n",
    "            # If it exists but on CPU, move it to GPU (or vice versa)\n",
    "            if self.pos_embed_prompt.device != device or self.pos_embed_prompt.dtype != dtype:\n",
    "                self.pos_embed_prompt = nn.Parameter(self.pos_embed_prompt.data.to(device=device, dtype=dtype))\n",
    "\n",
    "        cls_pos = base[:, :1, :]         # [1,1,D] on device\n",
    "        patch_pos = base[:, 1:, :]       # [1,N,D] on device\n",
    "\n",
    "        pos = torch.cat([cls_pos, self.pos_embed_prompt, patch_pos], dim=1)  # [1,1+M+N,D]\n",
    "        return pos\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B = x.shape[0]\n",
    "        patches = self.vit.patch_tokens(x)              # [B,N,D]\n",
    "        cls = self.vit.cls_token.expand(B, -1, -1)      # [B,1,D]\n",
    "        prompts = self.prompt(B)                        # [B,M,D]\n",
    "\n",
    "        tokens = torch.cat([cls, prompts, patches], dim=1)  # [B,1+M+N,D]\n",
    "        pos = self._build_pos_embed(tokens.shape[1]).to(tokens.device)\n",
    "        out = self.vit.forward_tokens(tokens, pos)          # [B,1+M+N,D]\n",
    "        feat = out[:, 0, :]                                 # CLS feature [B,D]\n",
    "        return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Prototype memory + NCM logits\n",
    "# ---------------------------\n",
    "class PrototypeMemory(nn.Module):\n",
    "    def __init__(self, feat_dim: int):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.register_buffer(\"prototypes\", torch.empty(0, feat_dim))\n",
    "        self.register_buffer(\"counts\", torch.empty(0))\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return int(self.prototypes.shape[0])\n",
    "\n",
    "    def ensure_size(self, C: int, device: torch.device):\n",
    "        if self.num_classes >= C:\n",
    "            return\n",
    "        old = self.num_classes\n",
    "        pad_proto = torch.zeros(C - old, self.feat_dim, device=device)\n",
    "        pad_cnt = torch.zeros(C - old, device=device)\n",
    "        if old == 0:\n",
    "            self.prototypes = pad_proto\n",
    "            self.counts = pad_cnt\n",
    "        else:\n",
    "            self.prototypes = torch.cat([self.prototypes.to(device), pad_proto], dim=0)\n",
    "            self.counts = torch.cat([self.counts.to(device), pad_cnt], dim=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_from_batch(self, feats: torch.Tensor, labels: torch.Tensor):\n",
    "        device = feats.device\n",
    "        max_label = int(labels.max().item())\n",
    "        self.ensure_size(max_label + 1, device)\n",
    "\n",
    "        for c in labels.unique():\n",
    "            c = int(c.item())\n",
    "            idx = labels == c\n",
    "            f_c = feats[idx]\n",
    "            k = f_c.shape[0]\n",
    "            if k == 0:\n",
    "                continue\n",
    "            mu_old = self.prototypes[c]\n",
    "            n_old = self.counts[c].clamp(min=0.0)\n",
    "            mu_new = (n_old * mu_old + f_c.sum(dim=0)) / (n_old + float(k))\n",
    "            self.prototypes[c] = mu_new\n",
    "            self.counts[c] = n_old + float(k)\n",
    "\n",
    "    def logits_ncm(self, feats: torch.Tensor, tau: float = 1.0, normalize: bool = True) -> torch.Tensor:\n",
    "        if self.num_classes == 0:\n",
    "            raise RuntimeError(\"Empty prototype memory.\")\n",
    "        proto = self.prototypes.to(feats.device)\n",
    "        h = feats\n",
    "        if normalize:\n",
    "            proto = l2_normalize(proto, dim=-1)\n",
    "            h = l2_normalize(h, dim=-1)\n",
    "        d2 = torch.cdist(h, proto, p=2) ** 2\n",
    "        return -d2 / tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2353381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Losses\n",
    "# ---------------------------\n",
    "def proto_alignment_loss(feats: torch.Tensor, labels: torch.Tensor, proto_mem: PrototypeMemory) -> torch.Tensor:\n",
    "    proto = proto_mem.prototypes.to(feats.device)\n",
    "    mu = proto[labels]\n",
    "    feats_n = l2_normalize(feats, dim=-1)\n",
    "    mu_n = l2_normalize(mu, dim=-1)\n",
    "    return ((feats_n - mu_n) ** 2).sum(dim=-1).mean()\n",
    "\n",
    "\n",
    "def kd_loss_logits(logits_teacher: torch.Tensor, logits_student: torch.Tensor, T: float = 2.0) -> torch.Tensor:\n",
    "    p_t = F.softmax(logits_teacher / T, dim=-1)\n",
    "    log_p_s = F.log_softmax(logits_student / T, dim=-1)\n",
    "    return F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T * T)\n",
    "\n",
    "\n",
    "def domain_shift_loss(feats_old: torch.Tensor, feats_new: torch.Tensor) -> torch.Tensor:\n",
    "    mu_old = l2_normalize(feats_old.mean(dim=0), dim=-1)\n",
    "    mu_new = l2_normalize(feats_new.mean(dim=0), dim=-1)\n",
    "    return ((mu_old - mu_new) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cebc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# System wrapper\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class FSCILConfig:\n",
    "    # model\n",
    "    img_size: int = 32\n",
    "    patch_size: int = 4\n",
    "    feat_dim: int = 256\n",
    "    depth: int = 6\n",
    "    heads: int = 8\n",
    "    num_prompts: int = 10\n",
    "\n",
    "    # optimization\n",
    "    base_epochs: int = 5\n",
    "    inc_epochs: int = 5\n",
    "    lr_base: float = 3e-4\n",
    "    lr_inc: float = 3e-4\n",
    "    weight_decay: float = 0.05\n",
    "\n",
    "    # FSCIL split\n",
    "    base_classes: int = 60\n",
    "    ways_per_session: int = 5\n",
    "    shots_per_class: int = 5\n",
    "    replay_max_per_class: int = 20\n",
    "    batch_size: int = 64\n",
    "\n",
    "    # losses\n",
    "    tau: float = 1.0\n",
    "    kd_T: float = 2.0\n",
    "    ema_alpha: float = 0.999\n",
    "    lam_proto: float = 1.0\n",
    "    lam_kd: float = 1.0\n",
    "    lam_domain: float = 0.5\n",
    "\n",
    "    seed: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8673c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSCILSystem(nn.Module):\n",
    "    def __init__(self, cfg: FSCILConfig, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "\n",
    "        # base prompt (persistent)\n",
    "        self.base_prompt = PromptModule(cfg.num_prompts, cfg.feat_dim).to(device)\n",
    "\n",
    "        # template ViT\n",
    "        vit_template = SimpleViT(\n",
    "            img_size=cfg.img_size,\n",
    "            patch_size=cfg.patch_size,\n",
    "            embed_dim=cfg.feat_dim,\n",
    "            depth=cfg.depth,\n",
    "            num_heads=cfg.heads,\n",
    "        ).to(device)\n",
    "\n",
    "        # stable = EMA teacher (persistent)\n",
    "        self.stable = PromptedViT(copy.deepcopy(vit_template), self.base_prompt, cfg.img_size, cfg.patch_size).to(device)\n",
    "        set_requires_grad(self.stable, False)\n",
    "\n",
    "        # plastic/session prompt are created per session (temporary)\n",
    "        self.plastic: Optional[PromptedViT] = None\n",
    "        self.session_prompt: Optional[PromptModule] = None\n",
    "\n",
    "        # prototype memory (persistent)\n",
    "        self.proto_mem = PrototypeMemory(cfg.feat_dim).to(device)\n",
    "\n",
    "        # keep vit template for plastic recreation\n",
    "        self._vit_template = vit_template\n",
    "\n",
    "    def new_plastic_for_session(self):\n",
    "        cfg = self.cfg\n",
    "        # plastic vit initialized from stable vit weights\n",
    "        vit = copy.deepcopy(self._vit_template).to(self.device)\n",
    "        vit.load_state_dict(self.stable.vit.state_dict(), strict=True)\n",
    "\n",
    "        # session prompt initialized from base prompt + small noise\n",
    "        P_base = self.base_prompt.prompts.detach()\n",
    "        sp = PromptModule(cfg.num_prompts, cfg.feat_dim).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            sp.prompts.copy_(P_base + 0.01 * torch.randn_like(P_base))\n",
    "\n",
    "        self.session_prompt = sp\n",
    "        self.plastic = PromptedViT(vit, self.session_prompt, cfg.img_size, cfg.patch_size).to(self.device)\n",
    "        set_requires_grad(self.plastic, True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def build_prototypes(self, loader: DataLoader):\n",
    "        self.stable.eval()\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            h = self.stable(x)\n",
    "            self.proto_mem.update_from_batch(h, y)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.stable.eval()\n",
    "        h = self.stable(x.to(self.device))\n",
    "        logits = self.proto_mem.logits_ncm(h, tau=self.cfg.tau, normalize=True)\n",
    "        return logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training / Evaluation\n",
    "# ---------------------------\n",
    "def accuracy(model: FSCILSystem, loader: DataLoader) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(model.device), y.to(model.device)\n",
    "        pred = model.predict(x)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(total, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a881239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training Base (with tqdm)\n",
    "# ---------------------------\n",
    "def train_base(model: FSCILSystem, base_loader: DataLoader):\n",
    "    cfg = model.cfg\n",
    "    device = model.device\n",
    "\n",
    "    # train a temporary plastic that uses BASE prompt (same as stable prompt)\n",
    "    plastic = PromptedViT(\n",
    "        copy.deepcopy(model._vit_template),\n",
    "        model.base_prompt,\n",
    "        cfg.img_size,\n",
    "        cfg.patch_size\n",
    "    ).to(device)\n",
    "    set_requires_grad(plastic, True)\n",
    "\n",
    "    # stable is EMA-updated only\n",
    "    model.stable.eval()\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        plastic.parameters(),\n",
    "        lr=cfg.lr_base,\n",
    "        weight_decay=cfg.weight_decay\n",
    "    )\n",
    "\n",
    "    plastic.train()\n",
    "    for ep in range(cfg.base_epochs):\n",
    "\n",
    "        epoch_bar = tqdm(\n",
    "            base_loader,\n",
    "            desc=f\"[Base] Epoch {ep+1}/{cfg.base_epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for x, y in epoch_bar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            h = plastic(x)  # [B,D]\n",
    "\n",
    "            # temporary linear head for base training only\n",
    "            if not hasattr(train_base, \"head\") or train_base.head.out_features <= int(y.max().item()):\n",
    "                C = int(y.max().item()) + 1\n",
    "                train_base.head = nn.Linear(cfg.feat_dim, C).to(device)\n",
    "                train_base.head_opt = torch.optim.AdamW(\n",
    "                    train_base.head.parameters(),\n",
    "                    lr=cfg.lr_base,\n",
    "                    weight_decay=cfg.weight_decay\n",
    "                )\n",
    "\n",
    "            logits = train_base.head(l2_normalize(h))\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            train_base.head_opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_base.head_opt.step()\n",
    "\n",
    "            # EMA: stable <- plastic (vit weights only)\n",
    "            ema_update(model.stable.vit, plastic.vit, alpha=cfg.ema_alpha)\n",
    "\n",
    "            # update tqdm bar\n",
    "            epoch_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        epoch_bar.close()\n",
    "\n",
    "    # Build prototypes using stable (and base prompt)\n",
    "    model.proto_mem.prototypes = model.proto_mem.prototypes[:0]\n",
    "    model.proto_mem.counts = model.proto_mem.counts[:0]\n",
    "    model.build_prototypes(base_loader)\n",
    "\n",
    "    print(f\"[Base] prototypes built: {model.proto_mem.num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59974031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training Incremental\n",
    "# ---------------------------\n",
    "\n",
    "def train_incremental(\n",
    "    model: FSCILSystem,\n",
    "    new_loader: DataLoader,\n",
    "    replay_loader: Optional[DataLoader],\n",
    "):\n",
    "    cfg = model.cfg\n",
    "    device = model.device\n",
    "\n",
    "    model.new_plastic_for_session()\n",
    "    assert model.plastic is not None\n",
    "    plastic = model.plastic\n",
    "\n",
    "    model.stable.eval()\n",
    "    plastic.train()\n",
    "\n",
    "    opt = torch.optim.AdamW(plastic.parameters(), lr=cfg.lr_inc, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    replay_iter = iter(replay_loader) if replay_loader is not None else None\n",
    "\n",
    "    for ep in range(cfg.inc_epochs):\n",
    "        for x_new, y_new in new_loader:\n",
    "            x_new, y_new = x_new.to(device), y_new.to(device)\n",
    "\n",
    "            # ---- new-class forward (plastic) ----\n",
    "            h_new = plastic(x_new)\n",
    "            logits_new = model.proto_mem.logits_ncm(h_new, tau=cfg.tau, normalize=True)\n",
    "            loss_cls = F.cross_entropy(logits_new, y_new)\n",
    "            loss_proto = proto_alignment_loss(h_new, y_new, model.proto_mem)\n",
    "\n",
    "            # ---- old-class forward (stable teacher + plastic student) ----\n",
    "            loss_kd = torch.tensor(0.0, device=device)\n",
    "            loss_dom = torch.tensor(0.0, device=device)\n",
    "\n",
    "            if replay_iter is not None:\n",
    "                try:\n",
    "                    x_old, y_old = next(replay_iter)\n",
    "                except StopIteration:\n",
    "                    replay_iter = iter(replay_loader)\n",
    "                    x_old, y_old = next(replay_iter)\n",
    "\n",
    "                x_old, y_old = x_old.to(device), y_old.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    h_old_s = model.stable(x_old)\n",
    "                    logits_old_s = model.proto_mem.logits_ncm(h_old_s, tau=cfg.tau, normalize=True)\n",
    "\n",
    "                h_old_p = plastic(x_old)\n",
    "                logits_old_p = model.proto_mem.logits_ncm(h_old_p, tau=cfg.tau, normalize=True)\n",
    "\n",
    "                loss_kd = kd_loss_logits(logits_old_s, logits_old_p, T=cfg.kd_T)\n",
    "                loss_dom = domain_shift_loss(h_old_s, h_new)\n",
    "\n",
    "            loss = loss_cls + cfg.lam_proto * loss_proto + cfg.lam_kd * loss_kd + cfg.lam_domain * loss_dom\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # EMA merge plastic->stable (vit weights only)\n",
    "            ema_update(model.stable.vit, plastic.vit, alpha=cfg.ema_alpha)\n",
    "\n",
    "            # Update prototypes for new classes\n",
    "            with torch.no_grad():\n",
    "                model.proto_mem.update_from_batch(h_new.detach(), y_new.detach())\n",
    "\n",
    "        print(f\"[Inc] epoch {ep+1}/{cfg.inc_epochs} | loss={loss.item():.4f}\")\n",
    "\n",
    "    # discard plastic/session prompt\n",
    "    model.plastic = None\n",
    "    model.session_prompt = None\n",
    "    print(f\"[Inc] session done. prototypes now: {model.proto_mem.num_classes}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87293918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Main: CIFAR-100 FSCIL\n",
    "# ---------------------------\n",
    "def main_cifar100(cfg: FSCILConfig):\n",
    "    seed_all(cfg.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # transforms (match cfg.img_size)\n",
    "    tf_train = T.Compose([\n",
    "        T.Resize((cfg.img_size, cfg.img_size)),\n",
    "        T.RandomCrop(cfg.img_size, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    tf_test = T.Compose([\n",
    "        T.Resize((cfg.img_size, cfg.img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=tf_train)\n",
    "    testset  = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=tf_test)\n",
    "\n",
    "    train_targets = list(trainset.targets)\n",
    "    test_targets = list(testset.targets)\n",
    "\n",
    "    base_cls, inc_sessions = make_fscil_splits(\n",
    "        targets=train_targets,\n",
    "        base_classes=cfg.base_classes,\n",
    "        ways_per_session=cfg.ways_per_session,\n",
    "        shots_per_class=cfg.shots_per_class,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "\n",
    "    # Build loaders\n",
    "    base_idx = indices_for_classes(train_targets, base_cls)\n",
    "    base_loader = DataLoader(Subset(trainset, base_idx), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Test loader: we evaluate on full test set (all classes)\n",
    "    test_loader = DataLoader(testset, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Replay buffer\n",
    "    replay = ReplayBuffer(max_per_class=cfg.replay_max_per_class, seed=cfg.seed)\n",
    "\n",
    "    # System\n",
    "    model = FSCILSystem(cfg, device=device).to(device)\n",
    "\n",
    "    print(\"\\n=== BASE TRAINING ===\")\n",
    "    train_base(model, base_loader)\n",
    "\n",
    "    # Add some base exemplars to replay\n",
    "    # (sample few indices from base set for replay memory)\n",
    "    replay.add_indices(train_targets, random.sample(base_idx, min(len(base_idx), cfg.replay_max_per_class * len(base_cls))))\n",
    "\n",
    "    acc0 = accuracy(model, test_loader)\n",
    "    print(f\"[Eval] After base: Acc(all test classes) = {acc0*100:.2f}%\")\n",
    "\n",
    "    # Incremental sessions\n",
    "    for s, sess_classes in enumerate(inc_sessions, start=1):\n",
    "        print(f\"\\n=== INCREMENTAL SESSION {s}/{len(inc_sessions)} | classes={sess_classes} ===\")\n",
    "\n",
    "        # new few-shot indices (shots per class)\n",
    "        new_idx = fewshot_indices_for_classes(train_targets, sess_classes, cfg.shots_per_class, seed=cfg.seed + s)\n",
    "        new_loader = DataLoader(Subset(trainset, new_idx), batch_size=min(cfg.batch_size, len(new_idx)), shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # replay loader from buffer (old classes)\n",
    "        replay_idx = replay.all_indices()\n",
    "        replay_loader = None\n",
    "        if len(replay_idx) > 0:\n",
    "            replay_loader = DataLoader(Subset(trainset, replay_idx), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # Train session\n",
    "        train_incremental(model, new_loader, replay_loader)\n",
    "\n",
    "        # Update replay with new indices\n",
    "        replay.add_indices(train_targets, new_idx)\n",
    "\n",
    "        acc = accuracy(model, test_loader)\n",
    "        print(f\"[Eval] After session {s}: Acc(all test classes) = {acc*100:.2f}%\")\n",
    "\n",
    "    print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cfg = FSCILConfig(\n",
    "        # CIFAR-100 recommended fast settings\n",
    "        img_size=32,\n",
    "        patch_size=4,     # 32/4=8 -> 64 patches\n",
    "        feat_dim=256,\n",
    "        depth=6,\n",
    "        heads=8,\n",
    "        num_prompts=10,\n",
    "\n",
    "        base_epochs=20,    # increase for better\n",
    "        inc_epochs=20,     # increase for better\n",
    "        lr_base=3e-4,\n",
    "        lr_inc=3e-4,\n",
    "\n",
    "        base_classes=60,\n",
    "        ways_per_session=5,\n",
    "        shots_per_class=5,\n",
    "        replay_max_per_class=20,\n",
    "        batch_size=128,\n",
    "\n",
    "        tau=1.0,\n",
    "        kd_T=2.0,\n",
    "        ema_alpha=0.999,\n",
    "        lam_proto=1.0,\n",
    "        lam_kd=1.0,\n",
    "        lam_domain=0.5,\n",
    "\n",
    "        seed=0\n",
    "    )\n",
    "    main_cifar100(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiface_generate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
